{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is going to be the most interesting one. Here I will make use of different techniques to make classifications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# text mining\n",
    "import spacy\n",
    "from sklearn.metrics import classification_report\n",
    "# machine learning\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, Activation, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all data frames\n",
    "data2000 = pd.read_csv(\"new_data_2000.csv\")\n",
    "data4000 = pd.read_csv(\"new_data_4000.csv\")\n",
    "data6000 = pd.read_csv(\"new_data_6000.csv\")\n",
    "data8000 = pd.read_csv(\"new_data_8000.csv\")\n",
    "data10000 = pd.read_csv(\"new_data_10000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>09.02.20 00:47</td>\n",
       "      <td>13459</td>\n",
       "      <td>72445</td>\n",
       "      <td>A great coach and a fantastic guy. His endorse...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.887483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 22:08</td>\n",
       "      <td>47880</td>\n",
       "      <td>215503</td>\n",
       "      <td>Pete Rose played Major League Baseball for 24 ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.320811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:48</td>\n",
       "      <td>9452</td>\n",
       "      <td>37402</td>\n",
       "      <td>Total and complete Endorsement for Debbie Lesk...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.755680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:40</td>\n",
       "      <td>17545</td>\n",
       "      <td>62484</td>\n",
       "      <td>Governor Cuomo wanted to see me this weekend. ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.491409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:01</td>\n",
       "      <td>27437</td>\n",
       "      <td>120598</td>\n",
       "      <td>We will not be touching your Social Security o...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.648076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>10245</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 16:02</td>\n",
       "      <td>24681</td>\n",
       "      <td>87739</td>\n",
       "      <td>Having a good relationship with Russia is a go...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.522362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>10246</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 13:03</td>\n",
       "      <td>16601</td>\n",
       "      <td>73661</td>\n",
       "      <td>Only reason the hacking of the poorly defended...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.567706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>10247</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 12:56</td>\n",
       "      <td>15401</td>\n",
       "      <td>60280</td>\n",
       "      <td>Intelligence stated very strongly there was ab...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.490432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>10248</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 04:53</td>\n",
       "      <td>13961</td>\n",
       "      <td>59218</td>\n",
       "      <td>Gross negligence by the Democratic National Co...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.746146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>10249</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 01:07</td>\n",
       "      <td>6657</td>\n",
       "      <td>42476</td>\n",
       "      <td>Happy Birthday @EricTrump ! https://www. faceb...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.973859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9794 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         username            date  retweets  favorites  \\\n",
       "0         0  realDonaldTrump  09.02.20 00:47     13459      72445   \n",
       "1         1  realDonaldTrump  08.02.20 22:08     47880     215503   \n",
       "2         2  realDonaldTrump  08.02.20 20:48      9452      37402   \n",
       "3         3  realDonaldTrump  08.02.20 20:40     17545      62484   \n",
       "4         4  realDonaldTrump  08.02.20 20:01     27437     120598   \n",
       "...     ...              ...             ...       ...        ...   \n",
       "2212  10245  realDonaldTrump  07.01.17 16:02     24681      87739   \n",
       "2213  10246  realDonaldTrump  07.01.17 13:03     16601      73661   \n",
       "2214  10247  realDonaldTrump  07.01.17 12:56     15401      60280   \n",
       "2215  10248  realDonaldTrump  07.01.17 04:53     13961      59218   \n",
       "2216  10249  realDonaldTrump  07.01.17 01:07      6657      42476   \n",
       "\n",
       "                                                   text  emotion  \\\n",
       "0     A great coach and a fantastic guy. His endorse...      joy   \n",
       "1     Pete Rose played Major League Baseball for 24 ...  sadness   \n",
       "2     Total and complete Endorsement for Debbie Lesk...      joy   \n",
       "3     Governor Cuomo wanted to see me this weekend. ...  sadness   \n",
       "4     We will not be touching your Social Security o...    anger   \n",
       "...                                                 ...      ...   \n",
       "2212  Having a good relationship with Russia is a go...  sadness   \n",
       "2213  Only reason the hacking of the poorly defended...  sadness   \n",
       "2214  Intelligence stated very strongly there was ab...  sadness   \n",
       "2215  Gross negligence by the Democratic National Co...  disgust   \n",
       "2216  Happy Birthday @EricTrump ! https://www. faceb...      joy   \n",
       "\n",
       "      emotion_probability  \n",
       "0                0.887483  \n",
       "1                0.320811  \n",
       "2                0.755680  \n",
       "3                0.491409  \n",
       "4                0.648076  \n",
       "...                   ...  \n",
       "2212             0.522362  \n",
       "2213             0.567706  \n",
       "2214             0.490432  \n",
       "2215             0.746146  \n",
       "2216             0.973859  \n",
       "\n",
       "[9794 rows x 8 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge data frames\n",
    "data = pd.concat([data2000,data4000,data6000,data8000,data10000])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all NaN emotion\n",
    "## via watson no classification possible\n",
    "data = data[data[\"emotion_probability\"] < 1.0] # remove those which could not be classified by Watson\n",
    "data = data[data[\"emotion_probability\"] != 0.0] #  pictures, links und hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9585, 8)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing - cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"entityrecognizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    result = []\n",
    "    \n",
    "    for token in doc: \n",
    "        if token.is_alpha == True: \n",
    "                result.append(token.lemma_)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "A great coach and a fantastic guy. His endorsement of me in Indiana was a very big deal! https:// twitter.com/kyle__boone/st atus/1226234981808250880 …\n",
      "--\n",
      "Pete Rose played Major League Baseball for 24 seasons, from 1963-1986, and had more hits, 4,256, than any other player (by a wide margin). He gambled, but only on his own team winning, and paid a decades long price. GET PETE ROSE INTO THE BASEBALL HALL OF FAME. It’s Time!\n",
      "--\n",
      "Total and complete Endorsement for Debbie Lesko! @RepDLesko Love Arizona. https:// twitter.com/repdlesko/stat us/1225484090754899969 …\n"
     ]
    }
   ],
   "source": [
    "# print first 3 text - not cleand\n",
    "for i in range(3):\n",
    "    print(\"--\")\n",
    "    print(data.text[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "A great coach and a fantastic guy His endorsement of me in Indiana be a very big deal\n",
      "--\n",
      "Pete Rose play Major League Baseball for season from and have much hit than any other player by a wide margin He gamble but only on his own team win and pay a decade long price GET PETE ROSE INTO THE BASEBALL HALL OF FAME -PRON- Time\n",
      "--\n",
      "Total and complete Endorsement for Debbie Lesko Love Arizona\n"
     ]
    }
   ],
   "source": [
    "# print first 3 text - cleaned\n",
    "for i in range(3):\n",
    "    print(\"--\")\n",
    "    print(' '.join(word for word in preprocess(data.text[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of all cleand texts\n",
    "text_preprocessed = []\n",
    "for i in range(data.shape[0]):\n",
    "    text_preprocessed.append(' '.join(word for word in preprocess(data.text[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessed text as column to the dataframe\n",
    "data[\"text_preprocessed\"] = text_preprocessed\n",
    "data = data[['index', 'username', 'date', 'retweets', 'favorites', 'text','text_preprocessed', 'emotion',\n",
    "       'emotion_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>09.02.20 00:47</td>\n",
       "      <td>13459</td>\n",
       "      <td>72445</td>\n",
       "      <td>A great coach and a fantastic guy. His endorse...</td>\n",
       "      <td>A great coach and a fantastic guy His endorsem...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.887483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 22:08</td>\n",
       "      <td>47880</td>\n",
       "      <td>215503</td>\n",
       "      <td>Pete Rose played Major League Baseball for 24 ...</td>\n",
       "      <td>Pete Rose play Major League Baseball for seaso...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.320811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:48</td>\n",
       "      <td>9452</td>\n",
       "      <td>37402</td>\n",
       "      <td>Total and complete Endorsement for Debbie Lesk...</td>\n",
       "      <td>Total and complete Endorsement for Debbie Lesk...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.755680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:40</td>\n",
       "      <td>17545</td>\n",
       "      <td>62484</td>\n",
       "      <td>Governor Cuomo wanted to see me this weekend. ...</td>\n",
       "      <td>Governor Cuomo want to see me this weekend He ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.491409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:01</td>\n",
       "      <td>27437</td>\n",
       "      <td>120598</td>\n",
       "      <td>We will not be touching your Social Security o...</td>\n",
       "      <td>We will not be touch your Social Security or M...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.648076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>10245</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 16:02</td>\n",
       "      <td>24681</td>\n",
       "      <td>87739</td>\n",
       "      <td>Having a good relationship with Russia is a go...</td>\n",
       "      <td>Having a good relationship with Russia be a go...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.522362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>10246</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 13:03</td>\n",
       "      <td>16601</td>\n",
       "      <td>73661</td>\n",
       "      <td>Only reason the hacking of the poorly defended...</td>\n",
       "      <td>Only reason the hack of the poorly defend DNC ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.567706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>10247</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 12:56</td>\n",
       "      <td>15401</td>\n",
       "      <td>60280</td>\n",
       "      <td>Intelligence stated very strongly there was ab...</td>\n",
       "      <td>Intelligence state very strongly there be abso...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.490432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9583</th>\n",
       "      <td>10248</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 04:53</td>\n",
       "      <td>13961</td>\n",
       "      <td>59218</td>\n",
       "      <td>Gross negligence by the Democratic National Co...</td>\n",
       "      <td>Gross negligence by the Democratic National Co...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.746146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9584</th>\n",
       "      <td>10249</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>07.01.17 01:07</td>\n",
       "      <td>6657</td>\n",
       "      <td>42476</td>\n",
       "      <td>Happy Birthday @EricTrump ! https://www. faceb...</td>\n",
       "      <td>Happy Birthday</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.973859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9585 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         username            date  retweets  favorites  \\\n",
       "0         0  realDonaldTrump  09.02.20 00:47     13459      72445   \n",
       "1         1  realDonaldTrump  08.02.20 22:08     47880     215503   \n",
       "2         2  realDonaldTrump  08.02.20 20:48      9452      37402   \n",
       "3         3  realDonaldTrump  08.02.20 20:40     17545      62484   \n",
       "4         4  realDonaldTrump  08.02.20 20:01     27437     120598   \n",
       "...     ...              ...             ...       ...        ...   \n",
       "9580  10245  realDonaldTrump  07.01.17 16:02     24681      87739   \n",
       "9581  10246  realDonaldTrump  07.01.17 13:03     16601      73661   \n",
       "9582  10247  realDonaldTrump  07.01.17 12:56     15401      60280   \n",
       "9583  10248  realDonaldTrump  07.01.17 04:53     13961      59218   \n",
       "9584  10249  realDonaldTrump  07.01.17 01:07      6657      42476   \n",
       "\n",
       "                                                   text  \\\n",
       "0     A great coach and a fantastic guy. His endorse...   \n",
       "1     Pete Rose played Major League Baseball for 24 ...   \n",
       "2     Total and complete Endorsement for Debbie Lesk...   \n",
       "3     Governor Cuomo wanted to see me this weekend. ...   \n",
       "4     We will not be touching your Social Security o...   \n",
       "...                                                 ...   \n",
       "9580  Having a good relationship with Russia is a go...   \n",
       "9581  Only reason the hacking of the poorly defended...   \n",
       "9582  Intelligence stated very strongly there was ab...   \n",
       "9583  Gross negligence by the Democratic National Co...   \n",
       "9584  Happy Birthday @EricTrump ! https://www. faceb...   \n",
       "\n",
       "                                      text_preprocessed  emotion  \\\n",
       "0     A great coach and a fantastic guy His endorsem...      joy   \n",
       "1     Pete Rose play Major League Baseball for seaso...  sadness   \n",
       "2     Total and complete Endorsement for Debbie Lesk...      joy   \n",
       "3     Governor Cuomo want to see me this weekend He ...  sadness   \n",
       "4     We will not be touch your Social Security or M...    anger   \n",
       "...                                                 ...      ...   \n",
       "9580  Having a good relationship with Russia be a go...  sadness   \n",
       "9581  Only reason the hack of the poorly defend DNC ...  sadness   \n",
       "9582  Intelligence state very strongly there be abso...  sadness   \n",
       "9583  Gross negligence by the Democratic National Co...  disgust   \n",
       "9584                                     Happy Birthday      joy   \n",
       "\n",
       "      emotion_probability  \n",
       "0                0.887483  \n",
       "1                0.320811  \n",
       "2                0.755680  \n",
       "3                0.491409  \n",
       "4                0.648076  \n",
       "...                   ...  \n",
       "9580             0.522362  \n",
       "9581             0.567706  \n",
       "9582             0.490432  \n",
       "9583             0.746146  \n",
       "9584             0.973859  \n",
       "\n",
       "[9585 rows x 9 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data - Train and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 80 percent as train data\n",
    "trainamound = round(data.shape[0]*80/100)\n",
    "train = data[0:trainamound]\n",
    "# leftover as test\n",
    "test = data[trainamound:]\n",
    "\n",
    "# split in X and y\n",
    "## train\n",
    "train_X = train.text_preprocessed\n",
    "#train_X = train.text\n",
    "train_y = train.emotion\n",
    "## test\n",
    "test_X = test.text_preprocessed\n",
    "test_y = test.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text_preprocessed\"]\n",
    "y = data[\"emotion\"]\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y , test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 7668\n",
      "Test: 1917\n",
      "Total: 9585\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\", len(X_train))\n",
    "print(\"Test:\", len(X_test))\n",
    "print(\"Total:\", len(X_train) +  len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy        3712\n",
       "sadness    1708\n",
       "disgust    1224\n",
       "anger       761\n",
       "fear        263\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy        874\n",
       "sadness    467\n",
       "disgust    328\n",
       "anger      188\n",
       "fear        60\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'fear', 'joy', 'sadness'], dtype=object)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating histogram \n",
    "fig, axs = plt.subplots(1, 1, \n",
    "                        figsize =(10, 7),  \n",
    "                        tight_layout = True) \n",
    "  \n",
    "axs.hist(y, bins = 20) \n",
    "  \n",
    "# Show plot\n",
    "plt.savefig(\"Histogram_emotions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3674\n",
       "4    1742\n",
       "1    1245\n",
       "0     746\n",
       "2     261\n",
       "dtype: int64"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    912\n",
       "4    433\n",
       "1    307\n",
       "0    203\n",
       "2     62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(261 + 62)*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [dummy classifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent : 0.479\n",
      "stratified : 0.323\n",
      "uniform : 0.204\n"
     ]
    }
   ],
   "source": [
    "# init strategies going to be unsed\n",
    "strategies = ['most_frequent', 'stratified', 'uniform']\n",
    "test_scores = []\n",
    "# run test with different strategies\n",
    "for strategy in strategies:\n",
    "    dummy_clf = DummyClassifier(strategy = strategy)\n",
    "    dummy_clf.fit(X_train,y_train)\n",
    "    dummy_score = round(dummy_clf.score(X_train,y_train),3)\n",
    "    test_scores.append(dummy_score)\n",
    "# print results\n",
    "for score,strategy in zip(test_scores,strategies):\n",
    "    print(strategy, \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_frequent : 0.476\n",
      "stratified : 0.302\n",
      "uniform : 0.207\n"
     ]
    }
   ],
   "source": [
    "# init strategies going to be unsed\n",
    "strategies = ['most_frequent', 'stratified', 'uniform']\n",
    "test_scores = []\n",
    "# run test with different strategies\n",
    "for strategy in strategies:\n",
    "    dummy_clf = DummyClassifier(strategy = strategy)\n",
    "    dummy_clf.fit(X_train,y_train)\n",
    "    dummy_score = round(dummy_clf.score(X_test,y_test),3)\n",
    "    test_scores.append(dummy_score)\n",
    "# print results\n",
    "for score,strategy in zip(test_scores,strategies):\n",
    "    print(strategy, \":\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBC - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 & 2 in pipeline\n",
    "# Step 1: vectorize speeches of train data\n",
    "# Step 2: instantiate and fit Bayes model\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "text_clf.fit(X_train, y_train)\n",
    "# make prediction\n",
    "predicted = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes classifier with default parameter is: 0.153\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_train)\n",
    "accuracy_MNB = round(np.mean(predicted == y_train),3)\n",
    "print(\"The accuracy of the Naive Bayes classifier with default parameter is: {}\".format(accuracy_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive Bayes classifier with default parameter is: 0.167\n"
     ]
    }
   ],
   "source": [
    "predicted = text_clf.predict(X_test)\n",
    "accuracy_MNB = round(np.mean(predicted == y_test),3)\n",
    "print(\"The accuracy of the Naive Bayes classifier with default parameter is: {}\".format(accuracy_MNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test,predicted,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBC - grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "# - vectorizer binary=False/True\n",
    "# - vectorizer ngram_range =(1, 1)\n",
    "# - \n",
    "parameters = {\n",
    "    'vect__binary': (True, False),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1,0.9, 0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, iid=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phillipholscher/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.2\n",
      "vect__binary: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.822\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "predicted_balanced_naivebayes = gs_clf.predict(X_train)\n",
    "# use classification report - precision, recall, F1 score, overfall accuracy\n",
    "mean_pred_balanced_naivebayes = round(np.mean(predicted_balanced_naivebayes == y_train),3)\n",
    "print(\"The accuracy is: {}\".format(mean_pred_balanced_naivebayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "predicted_balanced_naivebayes = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.644\n"
     ]
    }
   ],
   "source": [
    "# use classification report - precision, recall, F1 score, overfall accuracy\n",
    "mean_pred_balanced_naivebayes = round(np.mean(predicted_balanced_naivebayes == y_test),3)\n",
    "print(\"The accuracy is: {}\".format(mean_pred_balanced_naivebayes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test,predicted_balanced_naivebayes,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression - classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I copy pasted the whole code section of problem 2 in this cell\n",
    "\n",
    "# Step 1: vectorize speeches of train data\n",
    "# Step 2: instantiate and fit Bayes model\n",
    "text_clf2 = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression()),\n",
    "])\n",
    "\n",
    "parameters2 = {\n",
    "    'vect__binary': (True, False),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    'clf__solver': ('newton-cg', 'lbfgs', 'liblinear'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf2 = GridSearchCV(text_clf2, parameters2, cv=5, iid=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phillipholscher/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "gs_clf2 = gs_clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__solver: 'newton-cg'\n",
      "vect__binary: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters2.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf2.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.848\n"
     ]
    }
   ],
   "source": [
    "# make prediction with the trained logistic regression classifier\n",
    "predicted_balanced_logisticregression = gs_clf2.predict(X_train)\n",
    "# use classification report - precision, recall, F1 score, overfall accuracy\n",
    "mean_pred_balanced_logisticregression = round(np.mean(predicted_balanced_logisticregression == y_train),3)\n",
    "print(\"The accuracy is: {}\".format(mean_pred_balanced_logisticregression))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction with the trained logistic regression classifier\n",
    "predicted_balanced_logisticregression = gs_clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.719\n"
     ]
    }
   ],
   "source": [
    "# use classification report - precision, recall, F1 score, overfall accuracy\n",
    "mean_pred_balanced_logisticregression = round(np.mean(predicted_balanced_logisticregression == y_test),3)\n",
    "print(\"The accuracy is: {}\".format(mean_pred_balanced_logisticregression))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy       0.73      0.30      0.42       203\n",
      "     sadness       0.71      0.60      0.65       307\n",
      "       anger       0.75      0.05      0.09        62\n",
      "     disgust       0.76      0.94      0.84       912\n",
      "        fear       0.63      0.64      0.63       433\n",
      "\n",
      "    accuracy                           0.72      1917\n",
      "   macro avg       0.71      0.50      0.53      1917\n",
      "weighted avg       0.72      0.72      0.69      1917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted_balanced_logisticregression,target_names=emotions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert into lower case\n",
    "- convert the text into a preferred number representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore I´m going to define following variables\n",
    "- vocab_size\n",
    "- oov_token\n",
    "- max_length\n",
    "- padding_type\n",
    "- trunction_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_dim = 100\n",
    "max_length = 0\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "#training_size=160000\n",
    "#test_portion=.1\n",
    "\n",
    "#corpus = []\n",
    "vocab_size = 5853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check max length of tweet\n",
    "for tweet in data.text_preprocessed:\n",
    "    if len(tweet.split()) > max_length:\n",
    "        max_length = len(tweet.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize \n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'the': 2,\n",
       " 'be': 3,\n",
       " 'to': 4,\n",
       " 'and': 5,\n",
       " 'a': 6,\n",
       " 'of': 7,\n",
       " 'in': 8,\n",
       " 'have': 9,\n",
       " 'do': 10,\n",
       " 'that': 11,\n",
       " 'for': 12,\n",
       " 'i': 13,\n",
       " 'on': 14,\n",
       " 'great': 15,\n",
       " 'it': 16,\n",
       " 'they': 17,\n",
       " 'this': 18,\n",
       " 'with': 19,\n",
       " 'will': 20,\n",
       " 'our': 21,\n",
       " 'you': 22,\n",
       " 'we': 23,\n",
       " 'much': 24,\n",
       " 'he': 25,\n",
       " 'president': 26,\n",
       " 'all': 27,\n",
       " 'not': 28,\n",
       " 'very': 29,\n",
       " 'get': 30,\n",
       " 'by': 31,\n",
       " 'at': 32,\n",
       " 'so': 33,\n",
       " 'democrats': 34,\n",
       " 'no': 35,\n",
       " 'people': 36,\n",
       " 'country': 37,\n",
       " 'go': 38,\n",
       " 'but': 39,\n",
       " 'just': 40,\n",
       " 'thank': 41,\n",
       " 'pron': 42,\n",
       " 'my': 43,\n",
       " 'now': 44,\n",
       " 'big': 45,\n",
       " 'who': 46,\n",
       " 'nothing': 47,\n",
       " 'their': 48,\n",
       " 'trump': 49,\n",
       " 'good': 50,\n",
       " 'other': 51,\n",
       " 'say': 52,\n",
       " 'never': 53,\n",
       " 'make': 54,\n",
       " 'republican': 55,\n",
       " 'from': 56,\n",
       " 'would': 57,\n",
       " 'what': 58,\n",
       " 'up': 59,\n",
       " 'want': 60,\n",
       " 'year': 61,\n",
       " 'his': 62,\n",
       " 'impeachment': 63,\n",
       " 'new': 64,\n",
       " 'can': 65,\n",
       " 'news': 66,\n",
       " 'or': 67,\n",
       " 'should': 68,\n",
       " 'out': 69,\n",
       " 'me': 70,\n",
       " 'there': 71,\n",
       " 'fake': 72,\n",
       " 'call': 73,\n",
       " 'about': 74,\n",
       " 'many': 75,\n",
       " 'time': 76,\n",
       " 'american': 77,\n",
       " 'like': 78,\n",
       " 'see': 79,\n",
       " 'even': 80,\n",
       " 'work': 81,\n",
       " 'than': 82,\n",
       " 'win': 83,\n",
       " 'china': 84,\n",
       " 'your': 85,\n",
       " 'one': 86,\n",
       " 'know': 87,\n",
       " 'if': 88,\n",
       " 'house': 89,\n",
       " 'job': 90,\n",
       " 'democrat': 91,\n",
       " 'schiff': 92,\n",
       " 'party': 93,\n",
       " 'vote': 94,\n",
       " 'them': 95,\n",
       " 'united': 96,\n",
       " 'wrong': 97,\n",
       " 'which': 98,\n",
       " 'when': 99,\n",
       " 'state': 100,\n",
       " 'take': 101,\n",
       " 'come': 102,\n",
       " 'deal': 103,\n",
       " 'states': 104,\n",
       " 'him': 105,\n",
       " 'america': 106,\n",
       " 'well': 107,\n",
       " 'only': 108,\n",
       " 'way': 109,\n",
       " 'media': 110,\n",
       " 'look': 111,\n",
       " 'because': 112,\n",
       " 'witch': 113,\n",
       " 'over': 114,\n",
       " 'dems': 115,\n",
       " 'she': 116,\n",
       " 'after': 117,\n",
       " 'hunt': 118,\n",
       " 'strong': 119,\n",
       " 'bad': 120,\n",
       " 'give': 121,\n",
       " 'ever': 122,\n",
       " 'far': 123,\n",
       " 'history': 124,\n",
       " 'also': 125,\n",
       " 'thing': 126,\n",
       " 'think': 127,\n",
       " 'how': 128,\n",
       " 'pelosi': 129,\n",
       " 'today': 130,\n",
       " 'us': 131,\n",
       " 'why': 132,\n",
       " 'hoax': 133,\n",
       " 'ukraine': 134,\n",
       " 'again': 135,\n",
       " 'back': 136,\n",
       " 'whistleblower': 137,\n",
       " 'usa': 138,\n",
       " 'economy': 139,\n",
       " 'day': 140,\n",
       " 'military': 141,\n",
       " 'before': 142,\n",
       " 'election': 143,\n",
       " 'happen': 144,\n",
       " 'report': 145,\n",
       " 'congress': 146,\n",
       " 'fact': 147,\n",
       " 'fight': 148,\n",
       " 'two': 149,\n",
       " 'border': 150,\n",
       " 'help': 151,\n",
       " 'corrupt': 152,\n",
       " 'her': 153,\n",
       " 'must': 154,\n",
       " 'any': 155,\n",
       " 'last': 156,\n",
       " 'read': 157,\n",
       " 'long': 158,\n",
       " 'nancy': 159,\n",
       " 'crime': 160,\n",
       " 'down': 161,\n",
       " 'left': 162,\n",
       " 'against': 163,\n",
       " 'radical': 164,\n",
       " 'really': 165,\n",
       " 'hard': 166,\n",
       " 'where': 167,\n",
       " 'world': 168,\n",
       " 'trade': 169,\n",
       " 'into': 170,\n",
       " 'high': 171,\n",
       " 'senate': 172,\n",
       " 'totally': 173,\n",
       " 'try': 174,\n",
       " 'right': 175,\n",
       " 'record': 176,\n",
       " 'let': 177,\n",
       " 'too': 178,\n",
       " 'pay': 179,\n",
       " 'lose': 180,\n",
       " 'end': 181,\n",
       " 'love': 182,\n",
       " 'another': 183,\n",
       " 'story': 184,\n",
       " 'meet': 185,\n",
       " 'keep': 186,\n",
       " 'case': 187,\n",
       " 'federal': 188,\n",
       " 'then': 189,\n",
       " 'watch': 190,\n",
       " 'show': 191,\n",
       " 'governor': 192,\n",
       " 'adam': 193,\n",
       " 'administration': 194,\n",
       " 'low': 195,\n",
       " 'little': 196,\n",
       " 'include': 197,\n",
       " 'need': 198,\n",
       " 'total': 199,\n",
       " 'money': 200,\n",
       " 'allow': 201,\n",
       " 'always': 202,\n",
       " 'continue': 203,\n",
       " 'talk': 204,\n",
       " '\\ufeff1': 205,\n",
       " 'scam': 206,\n",
       " 'use': 207,\n",
       " 'carolina': 208,\n",
       " 'john': 209,\n",
       " 'night': 210,\n",
       " 'wall': 211,\n",
       " 'run': 212,\n",
       " 'north': 213,\n",
       " 'transcript': 214,\n",
       " 'york': 215,\n",
       " 'joe': 216,\n",
       " 'start': 217,\n",
       " 'poll': 218,\n",
       " 'some': 219,\n",
       " 'iran': 220,\n",
       " 'book': 221,\n",
       " 'ask': 222,\n",
       " 'congratulations': 223,\n",
       " 'jobs': 224,\n",
       " 'protect': 225,\n",
       " 'true': 226,\n",
       " 'believe': 227,\n",
       " 'under': 228,\n",
       " 'leave': 229,\n",
       " 'rate': 230,\n",
       " 'tell': 231,\n",
       " 'obama': 232,\n",
       " 'rating': 233,\n",
       " 'leader': 234,\n",
       " 'support': 235,\n",
       " 'hit': 236,\n",
       " 'crazy': 237,\n",
       " 'important': 238,\n",
       " 'ukrainian': 239,\n",
       " 'number': 240,\n",
       " 'put': 241,\n",
       " 'zero': 242,\n",
       " 'family': 243,\n",
       " 'fed': 244,\n",
       " 'interest': 245,\n",
       " 'complete': 246,\n",
       " 'p': 247,\n",
       " 'build': 248,\n",
       " 'become': 249,\n",
       " 'presidential': 250,\n",
       " 'court': 251,\n",
       " 'biden': 252,\n",
       " 'while': 253,\n",
       " 'mueller': 254,\n",
       " 'phone': 255,\n",
       " 'hear': 256,\n",
       " 'man': 257,\n",
       " 'word': 258,\n",
       " 'dollar': 259,\n",
       " 'place': 260,\n",
       " 'statement': 261,\n",
       " 'anything': 262,\n",
       " 'texas': 263,\n",
       " 'conversation': 264,\n",
       " 'both': 265,\n",
       " 'everything': 266,\n",
       " 'bring': 267,\n",
       " 'problem': 268,\n",
       " 'wonderful': 269,\n",
       " 'actually': 270,\n",
       " 'same': 271,\n",
       " 'lawyer': 272,\n",
       " 'pro': 273,\n",
       " 'already': 274,\n",
       " 'impeach': 275,\n",
       " 'order': 276,\n",
       " 'law': 277,\n",
       " 'louisiana': 278,\n",
       " 'market': 279,\n",
       " 'despite': 280,\n",
       " 'shifty': 281,\n",
       " 'white': 282,\n",
       " 'such': 283,\n",
       " 'hillary': 284,\n",
       " 'soon': 285,\n",
       " 'turkey': 286,\n",
       " 'doe': 287,\n",
       " 'its': 288,\n",
       " 'company': 289,\n",
       " 'together': 290,\n",
       " 'terrible': 291,\n",
       " 'yet': 292,\n",
       " 'lie': 293,\n",
       " 'dollars': 294,\n",
       " 'stop': 295,\n",
       " 'real': 296,\n",
       " 'billion': 297,\n",
       " 'incredible': 298,\n",
       " 'washington': 299,\n",
       " 'sign': 300,\n",
       " 'vets': 301,\n",
       " 'close': 302,\n",
       " 'may': 303,\n",
       " 'kill': 304,\n",
       " 'forward': 305,\n",
       " 'hate': 306,\n",
       " 'tariffs': 307,\n",
       " 'phony': 308,\n",
       " 'here': 309,\n",
       " 'million': 310,\n",
       " 'find': 311,\n",
       " 'happy': 312,\n",
       " 'release': 313,\n",
       " 'change': 314,\n",
       " 'endorsement': 315,\n",
       " 'price': 316,\n",
       " 'off': 317,\n",
       " 'respect': 318,\n",
       " 'fail': 319,\n",
       " 'pressure': 320,\n",
       " 'next': 321,\n",
       " 'witness': 322,\n",
       " 'nation': 323,\n",
       " 'force': 324,\n",
       " 'agree': 325,\n",
       " 'illegal': 326,\n",
       " 'process': 327,\n",
       " 'badly': 328,\n",
       " 'week': 329,\n",
       " 'approval': 330,\n",
       " 'stand': 331,\n",
       " 'amendment': 332,\n",
       " 'tremendous': 333,\n",
       " 'crooked': 334,\n",
       " 'reserve': 335,\n",
       " 'lead': 336,\n",
       " 'as': 337,\n",
       " 'tonight': 338,\n",
       " 'almost': 339,\n",
       " 'stock': 340,\n",
       " 'political': 341,\n",
       " 'friend': 342,\n",
       " 'spend': 343,\n",
       " 'reason': 344,\n",
       " 'donald': 345,\n",
       " 'hurt': 346,\n",
       " 'times': 347,\n",
       " 'guy': 348,\n",
       " 'speak': 349,\n",
       " 'attack': 350,\n",
       " 'energy': 351,\n",
       " 'point': 352,\n",
       " 'national': 353,\n",
       " 'drug': 354,\n",
       " 'fast': 355,\n",
       " 'information': 356,\n",
       " 'every': 357,\n",
       " 'minister': 358,\n",
       " 'interview': 359,\n",
       " 'something': 360,\n",
       " 'rally': 361,\n",
       " 'away': 362,\n",
       " 'everyone': 363,\n",
       " 'israel': 364,\n",
       " 'begin': 365,\n",
       " 'government': 366,\n",
       " 'please': 367,\n",
       " 'through': 368,\n",
       " 'dan': 369,\n",
       " 'person': 370,\n",
       " 'move': 371,\n",
       " 'large': 372,\n",
       " 'hope': 373,\n",
       " 'massive': 374,\n",
       " 'write': 375,\n",
       " 'question': 376,\n",
       " 'wow': 377,\n",
       " 'act': 378,\n",
       " 'sleepy': 379,\n",
       " 'since': 380,\n",
       " 'politician': 381,\n",
       " 'part': 382,\n",
       " 'justice': 383,\n",
       " 'hold': 384,\n",
       " 'congressman': 385,\n",
       " 'ago': 386,\n",
       " 'fraud': 387,\n",
       " 'robert': 388,\n",
       " 'around': 389,\n",
       " 'bill': 390,\n",
       " 'comey': 391,\n",
       " 'play': 392,\n",
       " 'russia': 393,\n",
       " 'nice': 394,\n",
       " 'remember': 395,\n",
       " 'quickly': 396,\n",
       " 'isis': 397,\n",
       " 'yesterday': 398,\n",
       " 'policy': 399,\n",
       " 'cut': 400,\n",
       " 'trial': 401,\n",
       " 'live': 402,\n",
       " 'tough': 403,\n",
       " 'ridiculous': 404,\n",
       " 'major': 405,\n",
       " 'own': 406,\n",
       " 'matt': 407,\n",
       " 'tomorrow': 408,\n",
       " 'is': 409,\n",
       " 'chuck': 410,\n",
       " 'california': 411,\n",
       " 'testify': 412,\n",
       " 'hand': 413,\n",
       " 'numb': 414,\n",
       " 'kurds': 415,\n",
       " 'security': 416,\n",
       " 'victory': 417,\n",
       " 'without': 418,\n",
       " 'during': 419,\n",
       " 'along': 420,\n",
       " 'maga': 421,\n",
       " 'usmca': 422,\n",
       " 'mark': 423,\n",
       " 'district': 424,\n",
       " 'create': 425,\n",
       " 'business': 426,\n",
       " 'three': 427,\n",
       " 'future': 428,\n",
       " 'post': 429,\n",
       " 'office': 430,\n",
       " 'clinton': 431,\n",
       " 'mean': 432,\n",
       " 'perhaps': 433,\n",
       " 'turn': 434,\n",
       " 'else': 435,\n",
       " 'foreign': 436,\n",
       " 'unfair': 437,\n",
       " 'open': 438,\n",
       " 'could': 439,\n",
       " 'beautiful': 440,\n",
       " 'fbi': 441,\n",
       " 'quo': 442,\n",
       " 'nato': 443,\n",
       " 'home': 444,\n",
       " 'announce': 445,\n",
       " 'though': 446,\n",
       " 'perfect': 447,\n",
       " 'campaign': 448,\n",
       " 'candidate': 449,\n",
       " 'mike': 450,\n",
       " 'honor': 451,\n",
       " 'lot': 452,\n",
       " 'safe': 453,\n",
       " 'care': 454,\n",
       " 'name': 455,\n",
       " 'power': 456,\n",
       " 'able': 457,\n",
       " 'quid': 458,\n",
       " 'syria': 459,\n",
       " 'fantastic': 460,\n",
       " 'partisan': 461,\n",
       " 'kentucky': 462,\n",
       " 'city': 463,\n",
       " 'senator': 464,\n",
       " 'economic': 465,\n",
       " 'game': 466,\n",
       " 'second': 467,\n",
       " 'war': 468,\n",
       " 'side': 469,\n",
       " 'possible': 470,\n",
       " 'false': 471,\n",
       " 'kevin': 472,\n",
       " 'whole': 473,\n",
       " 'successful': 474,\n",
       " 'break': 475,\n",
       " 'stay': 476,\n",
       " 'best': 477,\n",
       " 'credibility': 478,\n",
       " 'fire': 479,\n",
       " 'send': 480,\n",
       " 'former': 481,\n",
       " 'set': 482,\n",
       " 'due': 483,\n",
       " 'tax': 484,\n",
       " 'lamestream': 485,\n",
       " 'highly': 486,\n",
       " 'disaster': 487,\n",
       " 'fair': 488,\n",
       " 'morning': 489,\n",
       " 'southern': 490,\n",
       " 'unemployment': 491,\n",
       " 'immediately': 492,\n",
       " 'ambassador': 493,\n",
       " 'supreme': 494,\n",
       " 'treat': 495,\n",
       " 'between': 496,\n",
       " 'still': 497,\n",
       " 'florida': 498,\n",
       " 'prime': 499,\n",
       " 'base': 500,\n",
       " 'raise': 501,\n",
       " 'currency': 502,\n",
       " 'destroy': 503,\n",
       " 'iowa': 504,\n",
       " 'focus': 505,\n",
       " 'transcripts': 506,\n",
       " 'public': 507,\n",
       " 'cost': 508,\n",
       " 'mexico': 509,\n",
       " 'farmers': 510,\n",
       " 'car': 511,\n",
       " 'represent': 512,\n",
       " 'secretary': 513,\n",
       " 'level': 514,\n",
       " 'corruption': 515,\n",
       " 'fox': 516,\n",
       " 'control': 517,\n",
       " 'crowd': 518,\n",
       " 'general': 519,\n",
       " 'past': 520,\n",
       " 'investigate': 521,\n",
       " 'free': 522,\n",
       " 'enforcement': 523,\n",
       " 'sad': 524,\n",
       " 'leadership': 525,\n",
       " 'racist': 526,\n",
       " 'smart': 527,\n",
       " 'proud': 528,\n",
       " 'listen': 529,\n",
       " 'sure': 530,\n",
       " 'worker': 531,\n",
       " 'evidence': 532,\n",
       " 'consider': 533,\n",
       " 'investigation': 534,\n",
       " 'inflation': 535,\n",
       " 'idea': 536,\n",
       " 'member': 537,\n",
       " 'until': 538,\n",
       " 'ohio': 539,\n",
       " 'baltimore': 540,\n",
       " 'race': 541,\n",
       " 'speaker': 542,\n",
       " 'bernie': 543,\n",
       " 'debate': 544,\n",
       " 'fully': 545,\n",
       " 'truly': 546,\n",
       " 'taxis': 547,\n",
       " 'correct': 548,\n",
       " 'entire': 549,\n",
       " 'immigration': 550,\n",
       " 'borders': 551,\n",
       " 'horrible': 552,\n",
       " 'first': 553,\n",
       " 'elect': 554,\n",
       " 'france': 555,\n",
       " 'early': 556,\n",
       " 'team': 557,\n",
       " 'schumer': 558,\n",
       " 'strongly': 559,\n",
       " 'success': 560,\n",
       " 'plus': 561,\n",
       " 'south': 562,\n",
       " 'push': 563,\n",
       " 'save': 564,\n",
       " 'amaze': 565,\n",
       " 'full': 566,\n",
       " 'collusion': 567,\n",
       " 'hunter': 568,\n",
       " 'disgrace': 569,\n",
       " 'anyway': 570,\n",
       " 'involve': 571,\n",
       " 'these': 572,\n",
       " 'understand': 573,\n",
       " 'partner': 574,\n",
       " 'powell': 575,\n",
       " 'elijah': 576,\n",
       " 'hurricane': 577,\n",
       " '2': 578,\n",
       " 'polls': 579,\n",
       " 'forget': 580,\n",
       " 'serve': 581,\n",
       " 'especially': 582,\n",
       " 'easy': 583,\n",
       " 'sooo': 584,\n",
       " 'waste': 585,\n",
       " 'november': 586,\n",
       " 'approve': 587,\n",
       " 'god': 588,\n",
       " 'fraudulent': 589,\n",
       " 'absolutely': 590,\n",
       " 'source': 591,\n",
       " 'attorney': 592,\n",
       " 'dangerous': 593,\n",
       " 'billions': 594,\n",
       " 'check': 595,\n",
       " 'ready': 596,\n",
       " 'catch': 597,\n",
       " 'request': 598,\n",
       " 'decision': 599,\n",
       " 'product': 600,\n",
       " 'month': 601,\n",
       " 'el': 602,\n",
       " 'rebuild': 603,\n",
       " 'himself': 604,\n",
       " 'voter': 605,\n",
       " 'powerful': 606,\n",
       " 'defense': 607,\n",
       " 'growth': 608,\n",
       " 'late': 609,\n",
       " 'east': 610,\n",
       " 'cnn': 611,\n",
       " 'anyone': 612,\n",
       " 'judge': 613,\n",
       " 'prove': 614,\n",
       " 'event': 615,\n",
       " 'sit': 616,\n",
       " 'different': 617,\n",
       " 'pennsylvania': 618,\n",
       " 'clean': 619,\n",
       " 'action': 620,\n",
       " 'russian': 621,\n",
       " 'system': 622,\n",
       " 'failing': 623,\n",
       " 'police': 624,\n",
       " 'minnesota': 625,\n",
       " 'thanks': 626,\n",
       " 'finally': 627,\n",
       " 'nobody': 628,\n",
       " 'healthcare': 629,\n",
       " 'looking': 630,\n",
       " 'enjoy': 631,\n",
       " 'jim': 632,\n",
       " 'con': 633,\n",
       " 'face': 634,\n",
       " 'supporter': 635,\n",
       " 'iraq': 636,\n",
       " 'result': 637,\n",
       " 'few': 638,\n",
       " 'aid': 639,\n",
       " 'hour': 640,\n",
       " 'deliver': 641,\n",
       " 'choice': 642,\n",
       " 'demand': 643,\n",
       " 'truth': 644,\n",
       " 'fix': 645,\n",
       " 'add': 646,\n",
       " 'miss': 647,\n",
       " 'criminal': 648,\n",
       " 'potential': 649,\n",
       " 'testimony': 650,\n",
       " 'someone': 651,\n",
       " 'apologize': 652,\n",
       " 'putt': 653,\n",
       " 'obstruction': 654,\n",
       " 'impeachable': 655,\n",
       " 'either': 656,\n",
       " 'germany': 657,\n",
       " 'special': 658,\n",
       " 'deep': 659,\n",
       " 'edwards': 660,\n",
       " 'bishop': 661,\n",
       " 'decade': 662,\n",
       " 'drive': 663,\n",
       " 'except': 664,\n",
       " 'virginia': 665,\n",
       " 'nervous': 666,\n",
       " 'james': 667,\n",
       " 'weak': 668,\n",
       " 'xi': 669,\n",
       " 'charge': 670,\n",
       " 'commit': 671,\n",
       " 'wait': 672,\n",
       " 'head': 673,\n",
       " 'anywhere': 674,\n",
       " 'top': 675,\n",
       " 'admit': 676,\n",
       " 'anti': 677,\n",
       " 'expose': 678,\n",
       " 'blow': 679,\n",
       " 'chairman': 680,\n",
       " 'old': 681,\n",
       " 'progress': 682,\n",
       " 'drop': 683,\n",
       " 'importantly': 684,\n",
       " 'follow': 685,\n",
       " 'director': 686,\n",
       " 'oil': 687,\n",
       " 'steve': 688,\n",
       " 'kind': 689,\n",
       " 'pass': 690,\n",
       " 'bipartisan': 691,\n",
       " 'jay': 692,\n",
       " 'insurance': 693,\n",
       " 'bel': 694,\n",
       " 'mayor': 695,\n",
       " 'cummings': 696,\n",
       " 'kavanaugh': 697,\n",
       " 'paso': 698,\n",
       " 'politic': 699,\n",
       " 'everybody': 700,\n",
       " 'congressional': 701,\n",
       " 'receive': 702,\n",
       " 'primary': 703,\n",
       " 'community': 704,\n",
       " 'mess': 705,\n",
       " 'korea': 706,\n",
       " 'greatest': 707,\n",
       " 'disgust': 708,\n",
       " 'land': 709,\n",
       " 'agenda': 710,\n",
       " 'defend': 711,\n",
       " 'replace': 712,\n",
       " 'agreement': 713,\n",
       " 'itself': 714,\n",
       " 'enough': 715,\n",
       " 'safety': 716,\n",
       " 'concern': 717,\n",
       " 'majority': 718,\n",
       " 'michael': 719,\n",
       " 'probably': 720,\n",
       " 'opponent': 721,\n",
       " 'alabama': 722,\n",
       " 'plan': 723,\n",
       " 'return': 724,\n",
       " 'europe': 725,\n",
       " 'step': 726,\n",
       " 'middle': 727,\n",
       " 'hearing': 728,\n",
       " 'dirty': 729,\n",
       " 'greg': 730,\n",
       " 'mccarthy': 731,\n",
       " 'small': 732,\n",
       " 'inform': 733,\n",
       " 'dishonest': 734,\n",
       " 'spy': 735,\n",
       " 'completely': 736,\n",
       " 'navy': 737,\n",
       " 'buy': 738,\n",
       " 'eddie': 739,\n",
       " 'son': 740,\n",
       " 'woman': 741,\n",
       " 'across': 742,\n",
       " 'maybe': 743,\n",
       " 'closely': 744,\n",
       " 'fabricate': 745,\n",
       " 'african': 746,\n",
       " 'young': 747,\n",
       " 'mini': 748,\n",
       " 'speech': 749,\n",
       " 'beat': 750,\n",
       " 'claim': 751,\n",
       " 'rush': 752,\n",
       " 'negotiate': 753,\n",
       " 'thousand': 754,\n",
       " 'mention': 755,\n",
       " 'al': 756,\n",
       " 'historic': 757,\n",
       " 'homeless': 758,\n",
       " 'certain': 759,\n",
       " 'sorry': 760,\n",
       " 'mistake': 761,\n",
       " 'produce': 762,\n",
       " 'swamp': 763,\n",
       " 'term': 764,\n",
       " 'standard': 765,\n",
       " 'are': 766,\n",
       " 'chris': 767,\n",
       " 'pathetic': 768,\n",
       " 'ig': 769,\n",
       " 'nations': 770,\n",
       " 'numbers': 771,\n",
       " 'street': 772,\n",
       " 'paul': 773,\n",
       " 'clue': 774,\n",
       " 'sick': 775,\n",
       " 'aoc': 776,\n",
       " 'local': 777,\n",
       " 'angry': 778,\n",
       " 'answer': 779,\n",
       " 'prosecutor': 780,\n",
       " 'remain': 781,\n",
       " 'legal': 782,\n",
       " 'exactly': 783,\n",
       " 'amazon': 784,\n",
       " 'terrorist': 785,\n",
       " 'relationship': 786,\n",
       " 'official': 787,\n",
       " 'fisa': 788,\n",
       " 'mcconnell': 789,\n",
       " 'enemy': 790,\n",
       " 'target': 791,\n",
       " 'location': 792,\n",
       " 'shoot': 793,\n",
       " 'account': 794,\n",
       " 'peter': 795,\n",
       " 'victim': 796,\n",
       " 'increase': 797,\n",
       " 'service': 798,\n",
       " 'european': 799,\n",
       " 'was': 800,\n",
       " 'bank': 801,\n",
       " 'tighten': 802,\n",
       " 'amount': 803,\n",
       " 'dayton': 804,\n",
       " 'sue': 805,\n",
       " 'once': 806,\n",
       " 'opportunity': 807,\n",
       " 'hampshire': 808,\n",
       " 'blame': 809,\n",
       " 'hopefully': 810,\n",
       " 'innocent': 811,\n",
       " 'loves': 812,\n",
       " 'opinion': 813,\n",
       " 'soldier': 814,\n",
       " 'refuse': 815,\n",
       " 'life': 816,\n",
       " 'join': 817,\n",
       " 'press': 818,\n",
       " 'illegally': 819,\n",
       " 'iranian': 820,\n",
       " 'present': 821,\n",
       " 'medium': 822,\n",
       " 'explain': 823,\n",
       " 'seek': 824,\n",
       " 'articles': 825,\n",
       " 'manufacture': 826,\n",
       " 'representative': 827,\n",
       " 'appropriate': 828,\n",
       " 'fraudulently': 829,\n",
       " 'chinese': 830,\n",
       " 'bless': 831,\n",
       " 'weapon': 832,\n",
       " 'mitch': 833,\n",
       " 'four': 834,\n",
       " 'situation': 835,\n",
       " 'negotiation': 836,\n",
       " 'seem': 837,\n",
       " 'freedom': 838,\n",
       " 'negative': 839,\n",
       " 'air': 840,\n",
       " 'benefit': 841,\n",
       " 'jeff': 842,\n",
       " 'prescription': 843,\n",
       " 'trumpers': 844,\n",
       " 'inaccurate': 845,\n",
       " 'favor': 846,\n",
       " 'taxes': 847,\n",
       " 'current': 848,\n",
       " 'tim': 849,\n",
       " 'daca': 850,\n",
       " 'consumer': 851,\n",
       " 'minneapolis': 852,\n",
       " 'dorian': 853,\n",
       " 'congresswomen': 854,\n",
       " 'grow': 855,\n",
       " 'space': 856,\n",
       " 'defeat': 857,\n",
       " 'birthday': 858,\n",
       " 'made': 859,\n",
       " 'shape': 860,\n",
       " 'more': 861,\n",
       " 'cryin': 862,\n",
       " 'secure': 863,\n",
       " 'heading': 864,\n",
       " 'within': 865,\n",
       " 'peace': 866,\n",
       " 'abuse': 867,\n",
       " 'mind': 868,\n",
       " 'stuff': 869,\n",
       " 'greatly': 870,\n",
       " 'effort': 871,\n",
       " 'transparency': 872,\n",
       " 'most': 873,\n",
       " 'giant': 874,\n",
       " 'gun': 875,\n",
       " 'impeached': 876,\n",
       " 'rest': 877,\n",
       " 'rather': 878,\n",
       " 'clear': 879,\n",
       " 'fund': 880,\n",
       " 'bear': 881,\n",
       " 'bias': 882,\n",
       " 'presidency': 883,\n",
       " 'unable': 884,\n",
       " 'site': 885,\n",
       " 'treason': 886,\n",
       " 'veterans': 887,\n",
       " 'fall': 888,\n",
       " 'handle': 889,\n",
       " 'document': 890,\n",
       " 'rule': 891,\n",
       " 'legislation': 892,\n",
       " 'subject': 893,\n",
       " 'reveal': 894,\n",
       " 'decide': 895,\n",
       " 'learn': 896,\n",
       " 'quantitative': 897,\n",
       " 'organization': 898,\n",
       " 'meeting': 899,\n",
       " 'likewise': 900,\n",
       " 'reach': 901,\n",
       " 'impact': 902,\n",
       " 'mississippi': 903,\n",
       " 'scandal': 904,\n",
       " 'runoff': 905,\n",
       " 'loopholes': 906,\n",
       " 'stupid': 907,\n",
       " 'social': 908,\n",
       " 'feel': 909,\n",
       " 'continuation': 910,\n",
       " 'promise': 911,\n",
       " 'stage': 912,\n",
       " 'cover': 913,\n",
       " 'sound': 914,\n",
       " 'rip': 915,\n",
       " 'dead': 916,\n",
       " 'visit': 917,\n",
       " 'brian': 918,\n",
       " 'dream': 919,\n",
       " 'monitor': 920,\n",
       " 'presidents': 921,\n",
       " 'manufacturer': 922,\n",
       " 'auto': 923,\n",
       " 'heart': 924,\n",
       " 'none': 925,\n",
       " 'television': 926,\n",
       " 'judges': 927,\n",
       " 'king': 928,\n",
       " 'issue': 929,\n",
       " 'figure': 930,\n",
       " 'appreciate': 931,\n",
       " 'chance': 932,\n",
       " 'an': 933,\n",
       " 'suppose': 934,\n",
       " 'levin': 935,\n",
       " 'serious': 936,\n",
       " 'dismiss': 937,\n",
       " 'farmer': 938,\n",
       " 'phase': 939,\n",
       " 'suggest': 940,\n",
       " 'david': 941,\n",
       " 'incompetent': 942,\n",
       " 'myself': 943,\n",
       " 'fool': 944,\n",
       " 'group': 945,\n",
       " 'area': 946,\n",
       " 'patrol': 947,\n",
       " 'staff': 948,\n",
       " 'fine': 949,\n",
       " 'various': 950,\n",
       " 'wish': 951,\n",
       " 'anymore': 952,\n",
       " 'patriot': 953,\n",
       " 'therefore': 954,\n",
       " 'numerous': 955,\n",
       " 'inquiry': 956,\n",
       " 'water': 957,\n",
       " 'etc': 958,\n",
       " 'center': 959,\n",
       " 'recession': 960,\n",
       " 'based': 961,\n",
       " 'capture': 962,\n",
       " 'tate': 963,\n",
       " 'each': 964,\n",
       " 'tuesday': 965,\n",
       " 'october': 966,\n",
       " 'alternative': 967,\n",
       " 'endless': 968,\n",
       " 'shortly': 969,\n",
       " 'asylum': 970,\n",
       " 'short': 971,\n",
       " 'substantially': 972,\n",
       " 'nbc': 973,\n",
       " 'winner': 974,\n",
       " 'welcome': 975,\n",
       " 'earth': 976,\n",
       " 'solution': 977,\n",
       " 'bloomberg': 978,\n",
       " 'canada': 979,\n",
       " 'fairly': 980,\n",
       " 'fairness': 981,\n",
       " 'working': 982,\n",
       " 'leaving': 983,\n",
       " 'patriots': 984,\n",
       " 'expert': 985,\n",
       " 'die': 986,\n",
       " 'message': 987,\n",
       " 'addition': 988,\n",
       " 'bidens': 989,\n",
       " 'justices': 990,\n",
       " 'damage': 991,\n",
       " 'remove': 992,\n",
       " 'committee': 993,\n",
       " 'omar': 994,\n",
       " 'intelligence': 995,\n",
       " 'friday': 996,\n",
       " 'reporter': 997,\n",
       " 'demean': 998,\n",
       " 'joke': 999,\n",
       " 'constitution': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sequences = tokenizer.texts_to_sequences(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 15, 1896, 5, 6, 460, 348, 62, 315, 7, 70, 8, 3191, 3, 6, 29, 45, 103]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A great coach and a fantastic guy His endorsement of me in Indiana be a very big deal'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle - simple lstm for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.text_preprocessed\n",
    "Y = data.emotion\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/phillipholscher/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/phillipholscher/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 2460 samples, validate on 615 samples\n",
      "Epoch 1/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -29.1922 - accuracy: 0.1589 - val_loss: -73.4331 - val_accuracy: 0.1480\n",
      "Epoch 2/10\n",
      "2460/2460 [==============================] - 4s 2ms/step - loss: -105.3394 - accuracy: 0.1634 - val_loss: -153.5060 - val_accuracy: 0.1480\n",
      "Epoch 3/10\n",
      "2460/2460 [==============================] - 4s 2ms/step - loss: -185.9004 - accuracy: 0.1634 - val_loss: -242.1184 - val_accuracy: 0.1480\n",
      "Epoch 4/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -277.0322 - accuracy: 0.1634 - val_loss: -344.1022 - val_accuracy: 0.1480\n",
      "Epoch 5/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -381.1265 - accuracy: 0.1634 - val_loss: -457.3640 - val_accuracy: 0.1480\n",
      "Epoch 6/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -496.5544 - accuracy: 0.1634 - val_loss: -585.6325 - val_accuracy: 0.1480\n",
      "Epoch 7/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -626.5379 - accuracy: 0.1634 - val_loss: -729.7625 - val_accuracy: 0.1480\n",
      "Epoch 8/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -772.2792 - accuracy: 0.1634 - val_loss: -884.8545 - val_accuracy: 0.1480\n",
      "Epoch 9/10\n",
      "2460/2460 [==============================] - 5s 2ms/step - loss: -929.0254 - accuracy: 0.1634 - val_loss: -1056.8956 - val_accuracy: 0.1480\n",
      "Epoch 10/10\n",
      "2460/2460 [==============================] - 4s 2ms/step - loss: -1096.7834 - accuracy: 0.1634 - val_loss: -1237.7779 - val_accuracy: 0.1480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb32ef19fd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit training data\n",
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543/543 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: -1186.448\n",
      "  Accuracy: 0.168\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use knowledge of Tensorflow in practice specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed librareis\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer: This will handle the heavy lifting for us, generating the dictionary of  word encodings and creating vectors out of the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"emotion\"]\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y , test_size = 0.20)\n",
    "# Encode respond variable\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train_enc = le.transform(y_train)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'emotionless', 'fear', 'joy', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post' # cut of the back \n",
    "oov_tok = \"<OOV>\" # replace unknown token with this string\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train) # fit tokenizer on training\n",
    "word_index = tokenizer.word_index # look at word index\n",
    "sequences = tokenizer.texts_to_sequences(X_train) # convert sentences into sequences of numbers (word,number)(key,value)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type) # 120 words/numbers\n",
    "\n",
    "# testing sequences are tokenized based on the word index that was learned from the training words\n",
    "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 24)                46104     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 6)                 150       \n",
      "=================================================================\n",
      "Total params: 206,254\n",
      "Trainable params: 206,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # alternative\n",
    "    #tf.keras.layers.AveragePooling1D() #avg over vector\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7708 samples, validate on 1927 samples\n",
      "Epoch 1/10\n",
      "7708/7708 [==============================] - 1s 170us/sample - loss: 0.0247 - acc: 0.9969 - val_loss: 1.7492 - val_acc: 0.6082\n",
      "Epoch 2/10\n",
      "7708/7708 [==============================] - 2s 203us/sample - loss: 0.0176 - acc: 0.9979 - val_loss: 1.8655 - val_acc: 0.6015\n",
      "Epoch 3/10\n",
      "7708/7708 [==============================] - 1s 168us/sample - loss: 0.0131 - acc: 0.9983 - val_loss: 1.9160 - val_acc: 0.6056\n",
      "Epoch 4/10\n",
      "7708/7708 [==============================] - 1s 170us/sample - loss: 0.0097 - acc: 0.9991 - val_loss: 1.9681 - val_acc: 0.5983\n",
      "Epoch 5/10\n",
      "7708/7708 [==============================] - 1s 144us/sample - loss: 0.0076 - acc: 0.9994 - val_loss: 2.0477 - val_acc: 0.5983\n",
      "Epoch 6/10\n",
      "7708/7708 [==============================] - 1s 169us/sample - loss: 0.0060 - acc: 0.9995 - val_loss: 2.1071 - val_acc: 0.5973\n",
      "Epoch 7/10\n",
      "7708/7708 [==============================] - 1s 183us/sample - loss: 0.0046 - acc: 0.9996 - val_loss: 2.1759 - val_acc: 0.6015\n",
      "Epoch 8/10\n",
      "7708/7708 [==============================] - 2s 196us/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 2.2184 - val_acc: 0.5963\n",
      "Epoch 9/10\n",
      "7708/7708 [==============================] - 1s 152us/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 2.2933 - val_acc: 0.6009\n",
      "Epoch 10/10\n",
      "7708/7708 [==============================] - 2s 233us/sample - loss: 0.0022 - acc: 0.9997 - val_loss: 2.3087 - val_acc: 0.5968\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(padded, y_train_enc, epochs=num_epochs, validation_data=(testing_padded, y_test_enc))\n",
    "# can see overfitting in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.02466601816445326,\n",
       "  0.017638848471534053,\n",
       "  0.013110530327572515,\n",
       "  0.00967890881175938,\n",
       "  0.00761140825455988,\n",
       "  0.005976961238370637,\n",
       "  0.004625499418868524,\n",
       "  0.0036785637805906287,\n",
       "  0.0026995762875743432,\n",
       "  0.0021864293860795955],\n",
       " 'acc': [0.9968864,\n",
       "  0.9979242,\n",
       "  0.9983134,\n",
       "  0.99909186,\n",
       "  0.9993513,\n",
       "  0.9994811,\n",
       "  0.9996108,\n",
       "  0.9994811,\n",
       "  0.9996108,\n",
       "  0.99974054],\n",
       " 'val_loss': [1.7491817418688866,\n",
       "  1.8655402390648803,\n",
       "  1.916005531616884,\n",
       "  1.9681236335015013,\n",
       "  2.047706532676293,\n",
       "  2.10714890645091,\n",
       "  2.1759450109622365,\n",
       "  2.218388003330498,\n",
       "  2.2933002983775235,\n",
       "  2.308651911018423],\n",
       " 'val_acc': [0.6081993,\n",
       "  0.601453,\n",
       "  0.6056046,\n",
       "  0.5983394,\n",
       "  0.5983394,\n",
       "  0.5973015,\n",
       "  0.601453,\n",
       "  0.59626365,\n",
       "  0.6009341,\n",
       "  0.59678257]}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0] # output of the embedding\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
